<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>ChunkDownloader.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">jacoco.exec</a> &gt; <a href="index.source.html" class="el_package">com.databricks.jdbc.core</a> &gt; <span class="el_source">ChunkDownloader.java</span></div><h1>ChunkDownloader.java</h1><pre class="source lang-java linenums">package com.databricks.jdbc.core;

import com.databricks.jdbc.client.IDatabricksHttpClient;
import com.databricks.jdbc.client.http.DatabricksHttpClient;
import com.databricks.jdbc.client.impl.thrift.generated.TRowSet;
import com.databricks.jdbc.client.impl.thrift.generated.TSparkArrowResultLink;
import com.databricks.jdbc.client.sqlexec.ExternalLink;
import com.databricks.jdbc.client.sqlexec.ResultData;
import com.databricks.jdbc.client.sqlexec.ResultManifest;
import com.databricks.jdbc.core.types.CompressionType;
import com.databricks.sdk.service.sql.BaseChunkInfo;
import com.google.common.annotations.VisibleForTesting;
import java.util.Collection;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.ThreadFactory;
import java.util.concurrent.atomic.AtomicInteger;
import org.apache.logging.log4j.LogManager;
import org.apache.logging.log4j.Logger;

/** Class to manage Arrow chunks and fetch them on proactive basis. */
public class ChunkDownloader {

<span class="fc" id="L25">  private static final Logger logger = LogManager.getLogger(ChunkDownloader.class);</span>
  private static final String CHUNKS_DOWNLOADER_THREAD_POOL_PREFIX =
      &quot;databricks-jdbc-chunks-downloader-&quot;;
  private final IDatabricksSession session;
  private final String statementId;
  private final long totalChunks;
  private final ExecutorService chunkDownloaderExecutorService;
  private final IDatabricksHttpClient httpClient;
  private static int chunksDownloaderThreadPoolSize;
  private Long currentChunkIndex;
  private long nextChunkToDownload;
  private Long totalChunksInMemory;
  private long allowedChunksInMemory;
  private boolean isClosed;

  ConcurrentHashMap&lt;Long, ArrowResultChunk&gt; chunkIndexToChunksMap;

  ChunkDownloader(
      String statementId,
      ResultManifest resultManifest,
      ResultData resultData,
      IDatabricksSession session,
      int chunksDownloaderThreadPoolSize) {
<span class="fc" id="L48">    this(</span>
        statementId,
        resultManifest,
        resultData,
        session,
<span class="fc" id="L53">        DatabricksHttpClient.getInstance(session.getConnectionContext()),</span>
        chunksDownloaderThreadPoolSize);
<span class="fc" id="L55">  }</span>

  @VisibleForTesting
  ChunkDownloader(
      String statementId,
      ResultManifest resultManifest,
      ResultData resultData,
      IDatabricksSession session,
      IDatabricksHttpClient httpClient,
<span class="fc" id="L64">      int chunksDownloaderThreadPoolSize) {</span>
<span class="fc" id="L65">    this.chunksDownloaderThreadPoolSize = chunksDownloaderThreadPoolSize;</span>
<span class="fc" id="L66">    this.chunkDownloaderExecutorService = createChunksDownloaderExecutorService();</span>
<span class="fc" id="L67">    this.httpClient = httpClient;</span>
<span class="fc" id="L68">    this.session = session;</span>
<span class="fc" id="L69">    this.statementId = statementId;</span>
<span class="fc" id="L70">    this.totalChunks = resultManifest.getTotalChunkCount();</span>
<span class="fc" id="L71">    this.chunkIndexToChunksMap = initializeChunksMap(resultManifest, resultData, statementId);</span>
<span class="fc" id="L72">    initializeData();</span>
<span class="fc" id="L73">  }</span>

  ChunkDownloader(
      String statementId,
      TRowSet resultData,
      IDatabricksSession session,
      int chunksDownloaderThreadPoolSize) {
<span class="fc" id="L80">    this(</span>
        statementId,
        resultData,
        session,
<span class="fc" id="L84">        DatabricksHttpClient.getInstance(session.getConnectionContext()),</span>
        chunksDownloaderThreadPoolSize);
<span class="fc" id="L86">  }</span>

  @VisibleForTesting
  ChunkDownloader(
      String statementId,
      TRowSet resultData,
      IDatabricksSession session,
      IDatabricksHttpClient httpClient,
<span class="fc" id="L94">      int chunksDownloaderThreadPoolSize) {</span>
<span class="fc" id="L95">    this.chunksDownloaderThreadPoolSize = chunksDownloaderThreadPoolSize;</span>
<span class="fc" id="L96">    this.chunkDownloaderExecutorService = createChunksDownloaderExecutorService();</span>
<span class="fc" id="L97">    this.httpClient = httpClient;</span>
<span class="fc" id="L98">    this.session = session;</span>
<span class="fc" id="L99">    this.statementId = statementId;</span>
<span class="fc" id="L100">    this.totalChunks = resultData.getResultLinksSize();</span>
<span class="fc" id="L101">    this.chunkIndexToChunksMap = initializeChunksMap(resultData, statementId);</span>
<span class="fc" id="L102">    initializeData();</span>
<span class="fc" id="L103">  }</span>

  private static ConcurrentHashMap&lt;Long, ArrowResultChunk&gt; initializeChunksMap(
      TRowSet resultData, String statementId) {
<span class="fc" id="L107">    ConcurrentHashMap&lt;Long, ArrowResultChunk&gt; chunkIndexMap = new ConcurrentHashMap&lt;&gt;();</span>
<span class="fc" id="L108">    long chunkIndex = 0;</span>
<span class="fc bfc" id="L109" title="All 2 branches covered.">    if (resultData.getResultLinksSize() == 0) {</span>
<span class="fc" id="L110">      return chunkIndexMap;</span>
    }
<span class="fc bfc" id="L112" title="All 2 branches covered.">    for (TSparkArrowResultLink resultLink : resultData.getResultLinks()) {</span>
      // TODO : add compression
<span class="fc" id="L114">      chunkIndexMap.put(</span>
<span class="fc" id="L115">          chunkIndex,</span>
          new ArrowResultChunk(chunkIndex, resultLink, statementId, CompressionType.NONE));
<span class="fc" id="L117">      chunkIndex++;</span>
<span class="fc" id="L118">    }</span>
<span class="fc" id="L119">    return chunkIndexMap;</span>
  }

  private static ExecutorService createChunksDownloaderExecutorService() {
<span class="fc" id="L123">    ThreadFactory threadFactory =</span>
<span class="fc" id="L124">        new ThreadFactory() {</span>
<span class="fc" id="L125">          private AtomicInteger threadCount = new AtomicInteger(1);</span>

          public Thread newThread(final Runnable r) {
<span class="fc" id="L128">            final Thread thread = new Thread(r);</span>
<span class="fc" id="L129">            thread.setName(CHUNKS_DOWNLOADER_THREAD_POOL_PREFIX + threadCount.getAndIncrement());</span>
<span class="fc" id="L130">            thread.setDaemon(true);</span>
<span class="fc" id="L131">            return thread;</span>
          }
        };
<span class="fc" id="L134">    return Executors.newFixedThreadPool(chunksDownloaderThreadPoolSize, threadFactory);</span>
  }

  /**
   * Fetches the chunk for the given index. If chunk is not already downloaded, will download the
   * chunk first
   *
   * @return the chunk at given index
   */
  public ArrowResultChunk getChunk() throws DatabricksSQLException {
<span class="pc bpc" id="L144" title="1 of 2 branches missed.">    if (currentChunkIndex &lt; 0) {</span>
<span class="nc" id="L145">      return null;</span>
    }
<span class="fc" id="L147">    ArrowResultChunk chunk = chunkIndexToChunksMap.get(currentChunkIndex);</span>
<span class="fc" id="L148">    httpClient.closeExpiredAndIdleConnections();</span>
<span class="fc" id="L149">    synchronized (chunk) {</span>
      try {
<span class="fc bfc" id="L151" title="All 2 branches covered.">        while (!isDownloadComplete(chunk.getStatus())) {</span>
<span class="fc" id="L152">          chunk.wait();</span>
        }
<span class="pc bpc" id="L154" title="1 of 2 branches missed.">        if (chunk.getStatus() != ArrowResultChunk.ChunkStatus.DOWNLOAD_SUCCEEDED) {</span>
<span class="nc" id="L155">          throw new DatabricksSQLException(chunk.getErrorMessage());</span>
        }
<span class="nc" id="L157">      } catch (InterruptedException e) {</span>
<span class="nc" id="L158">        logger.info(</span>
            &quot;Caught interrupted exception while waiting for chunk [%s] for statement [%s]. Exception [%s]&quot;,
<span class="nc" id="L160">            chunk.getChunkIndex(), statementId, e);</span>
<span class="fc" id="L161">      }</span>
<span class="fc" id="L162">    }</span>

<span class="fc" id="L164">    return chunk;</span>
  }

  boolean hasNextChunk() {
<span class="fc bfc" id="L168" title="All 2 branches covered.">    return currentChunkIndex &lt; totalChunks - 1;</span>
  }

  boolean next() {
<span class="fc bfc" id="L172" title="All 2 branches covered.">    if (currentChunkIndex &gt;= 0) {</span>
      // release current chunk
<span class="fc" id="L174">      releaseChunk();</span>
    }
<span class="pc bpc" id="L176" title="1 of 2 branches missed.">    if (!hasNextChunk()) {</span>
<span class="nc" id="L177">      return false;</span>
    }
    // go to next chunk
<span class="fc" id="L180">    currentChunkIndex++;</span>
<span class="fc" id="L181">    return true;</span>
  }

  private boolean isDownloadComplete(ArrowResultChunk.ChunkStatus status) {
<span class="pc bpc" id="L185" title="2 of 6 branches missed.">    return status == ArrowResultChunk.ChunkStatus.DOWNLOAD_SUCCEEDED</span>
        || status == ArrowResultChunk.ChunkStatus.DOWNLOAD_FAILED
        || status == ArrowResultChunk.ChunkStatus.DOWNLOAD_FAILED_ABORTED;
  }

  void downloadProcessed(long chunkIndex) {
<span class="fc" id="L191">    ArrowResultChunk chunk = chunkIndexToChunksMap.get(chunkIndex);</span>
<span class="fc" id="L192">    synchronized (chunk) {</span>
<span class="fc" id="L193">      chunk.notify();</span>
<span class="fc" id="L194">    }</span>
<span class="fc" id="L195">  }</span>

  void downloadLinks(long chunkIndexToDownloadLink) throws DatabricksSQLException {
<span class="fc" id="L198">    Collection&lt;ExternalLink&gt; chunks =</span>
<span class="fc" id="L199">        session.getDatabricksClient().getResultChunks(statementId, chunkIndexToDownloadLink);</span>
<span class="fc bfc" id="L200" title="All 2 branches covered.">    for (ExternalLink chunkLink : chunks) {</span>
<span class="fc" id="L201">      setChunkLink(chunkLink);</span>
<span class="fc" id="L202">    }</span>
<span class="fc" id="L203">  }</span>

  /** Release the memory for previous chunk since it is already consumed */
  public void releaseChunk() {
<span class="pc bpc" id="L207" title="1 of 2 branches missed.">    if (chunkIndexToChunksMap.get(currentChunkIndex).releaseChunk()) {</span>
<span class="fc" id="L208">      totalChunksInMemory--;</span>
<span class="fc" id="L209">      downloadNextChunks();</span>
    }
<span class="fc" id="L211">  }</span>

  /**
   * Initialize chunk with external link details
   *
   * @param chunkLink external link details for chunk
   */
  void setChunkLink(ExternalLink chunkLink) {
<span class="pc bpc" id="L219" title="1 of 2 branches missed.">    if (!isDownloadComplete(chunkIndexToChunksMap.get(chunkLink.getChunkIndex()).getStatus())) {</span>
<span class="fc" id="L220">      chunkIndexToChunksMap.get(chunkLink.getChunkIndex()).setChunkLink(chunkLink);</span>
    }
<span class="fc" id="L222">  }</span>

  /** Fetches total chunks that we have in memory */
  long getTotalChunksInMemory() {
<span class="nc" id="L226">    return totalChunksInMemory;</span>
  }

  /** Release all chunks from memory. This would be called when result-set has been closed. */
  void releaseAllChunks() {
<span class="fc" id="L231">    this.isClosed = true;</span>
<span class="fc" id="L232">    this.chunkDownloaderExecutorService.shutdownNow();</span>
<span class="fc" id="L233">    this.chunkIndexToChunksMap.values().forEach(chunk -&gt; chunk.releaseChunk());</span>
<span class="fc" id="L234">    httpClient.closeExpiredAndIdleConnections();</span>
<span class="fc" id="L235">  }</span>

  void downloadNextChunks() {
<span class="pc bpc" id="L238" title="1 of 4 branches missed.">    while (!this.isClosed</span>
        &amp;&amp; nextChunkToDownload &lt; totalChunks
<span class="pc bpc" id="L240" title="1 of 2 branches missed.">        &amp;&amp; totalChunksInMemory &lt; allowedChunksInMemory) {</span>
<span class="fc" id="L241">      ArrowResultChunk chunk = chunkIndexToChunksMap.get(nextChunkToDownload);</span>
<span class="pc bpc" id="L242" title="1 of 2 branches missed.">      if (chunk.getStatus() != ArrowResultChunk.ChunkStatus.DOWNLOAD_SUCCEEDED) {</span>
<span class="fc" id="L243">        this.chunkDownloaderExecutorService.submit(</span>
            new SingleChunkDownloader(chunk, httpClient, this));
<span class="fc" id="L245">        totalChunksInMemory++;</span>
      }
<span class="fc" id="L247">      nextChunkToDownload++;</span>
<span class="fc" id="L248">    }</span>
<span class="fc" id="L249">  }</span>

  void initializeData() {
    // No chunks are downloaded, we need to start from first one
<span class="fc" id="L253">    this.nextChunkToDownload = 0;</span>
    // Initialize current chunk to -1, since we don't have anything to read
<span class="fc" id="L255">    this.currentChunkIndex = -1L;</span>
    // We don't have any chunk in downloaded yet
<span class="fc" id="L257">    this.totalChunksInMemory = 0L;</span>
    // Number of worker threads are directly linked to allowed chunks in memory
<span class="fc" id="L259">    this.allowedChunksInMemory = Math.min(chunksDownloaderThreadPoolSize, totalChunks);</span>
<span class="fc" id="L260">    this.isClosed = false;</span>
    // The first link is available
<span class="fc" id="L262">    this.downloadNextChunks();</span>
<span class="fc" id="L263">  }</span>

  private static ConcurrentHashMap&lt;Long, ArrowResultChunk&gt; initializeChunksMap(
      ResultManifest resultManifest, ResultData resultData, String statementId) {
<span class="fc" id="L267">    ConcurrentHashMap&lt;Long, ArrowResultChunk&gt; chunkIndexMap = new ConcurrentHashMap&lt;&gt;();</span>
<span class="fc bfc" id="L268" title="All 2 branches covered.">    if (resultManifest.getTotalChunkCount() == 0) {</span>
<span class="fc" id="L269">      return chunkIndexMap;</span>
    }
<span class="fc bfc" id="L271" title="All 2 branches covered.">    for (BaseChunkInfo chunkInfo : resultManifest.getChunks()) {</span>
      // TODO: Add logging to check data (in bytes) from server and in root allocator.
      //  If they are close, we can directly assign the number of bytes as the limit with a small
      // buffer.
<span class="fc" id="L275">      chunkIndexMap.put(</span>
<span class="fc" id="L276">          chunkInfo.getChunkIndex(),</span>
<span class="fc" id="L277">          new ArrowResultChunk(chunkInfo, statementId, resultManifest.getCompressionType()));</span>
<span class="fc" id="L278">    }</span>

<span class="fc bfc" id="L280" title="All 2 branches covered.">    for (ExternalLink externalLink : resultData.getExternalLinks()) {</span>
<span class="fc" id="L281">      chunkIndexMap.get(externalLink.getChunkIndex()).setChunkLink(externalLink);</span>
<span class="fc" id="L282">    }</span>
<span class="fc" id="L283">    return chunkIndexMap;</span>
  }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.8.202204050719</span></div></body></html>